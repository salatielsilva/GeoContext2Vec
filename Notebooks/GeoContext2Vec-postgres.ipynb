{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psycopg2\n",
    "!pip install gensim==3.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2 as postgres\n",
    "import psycopg2.extras\n",
    "import math\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "from sshtunnel import SSHTunnelForwarder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect():\n",
    "    \"\"\"\n",
    "    Establishes a connection to a PostgreSQL database.\n",
    "\n",
    "    Returns:\n",
    "        psycopg2.extensions.connection: A connection object to the database.\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            host=\"localhost\",\n",
    "            database=\"austin_test\",  # Database name\n",
    "            user=\"postgres\",         # Database username\n",
    "            password=\"root\"          # Database password\n",
    "        )\n",
    "    except psycopg2.Error as e:\n",
    "        print(e)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closeConnection(conn):\n",
    "    \"\"\"\n",
    "    Closes the connection to a PostgreSQL database.\n",
    "\n",
    "    Args:\n",
    "        conn (psycopg2.extensions.connection): A connection object to the database.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the connection was successfully closed, False otherwise.\n",
    "    \"\"\"\n",
    "    success = False\n",
    "    try:\n",
    "        conn.close()\n",
    "        success = True\n",
    "    except psycopg2.Error as e:\n",
    "        print(e)\n",
    "    \n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeQuery(conn, sql):\n",
    "    \"\"\"\n",
    "    Executes a SQL query on a PostgreSQL database.\n",
    "\n",
    "    Args:\n",
    "        conn (psycopg2.extensions.connection): A connection object to the database.\n",
    "        sql (str): The SQL query to execute.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of records (tuples) retrieved from the database.\n",
    "    \"\"\"\n",
    "    record = None\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(sql)\n",
    "        record = cur.fetchall()\n",
    "        cur.close()\n",
    "    except psycopg2.Error as e:\n",
    "        print(e)\n",
    "        cur.execute(\"ROLLBACK\")\n",
    "        cur.close()\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeInsert(conn, sql):\n",
    "    \"\"\"\n",
    "    Executes an SQL INSERT statement on a PostgreSQL database.\n",
    "\n",
    "    Args:\n",
    "        conn (psycopg2.extensions.connection): A connection object to the database.\n",
    "        sql (str): The SQL INSERT statement to execute.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the insertion was successful, False otherwise.\n",
    "    \"\"\"\n",
    "    success = False\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(sql)\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        success = True\n",
    "    except psycopg2.Error as e:\n",
    "        print(e)\n",
    "        cur.execute(\"ROLLBACK\")\n",
    "        cur.close()\n",
    "\n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPOIInformation(conn, business_id):\n",
    "    \"\"\"\n",
    "    Retrieves information about a Point of Interest (POI) based on its ID.\n",
    "\n",
    "    Args:\n",
    "        conn (psycopg2.extensions.connection): A connection object to the database.\n",
    "        business_id (str): The unique ID of the POI.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples containing checkin count and name for the specified POI.\n",
    "    \"\"\"\n",
    "     sql = \"\"\"\n",
    "        SELECT checkin_count, name FROM pois_information WHERE id  = \\'\"\"\"+str(business_id)+ \"\"\"\\'\n",
    "    ;\"\"\"\n",
    "\n",
    "    result = executeQuery(conn, sql)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all points in the bin centered around a POI, along with their information (categories and check-in counts)\n",
    "def getBinPOIsInformation(conn, business_id, bin_number):\n",
    "    \"\"\"\n",
    "    Retrieves information about all points within a specific bin centered around a given POI.\n",
    "\n",
    "    Args:\n",
    "        conn (psycopg2.extensions.connection): Database connection.\n",
    "        business_id (str): ID of the central POI.\n",
    "        bin_number (int): Bin number.\n",
    "\n",
    "    Returns:\n",
    "        list: List of dictionaries containing information for each point in the bin.\n",
    "            Each dictionary includes keys: 'fk_poi_id_context', 'name', 'level', 'checkin_count', and 'distance_m'.\n",
    "    \"\"\"\n",
    "    result = None\n",
    "\n",
    "    sql = \"\"\"\n",
    "        SELECT fk_poi_id_context, name, level, checkin_count, distance_m \n",
    "        FROM bins_pois_information \n",
    "        WHERE fk_poi_id_center = \\'\"\"\"+str(business_id)+\"\"\"\\' AND fk_bin_number = \"\"\"+str(bin_number)+\"\"\";\"\"\"\n",
    "\n",
    "    result = executeQuery(conn, sql)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that retrieves information from a materialized view related to OSM\n",
    "def getBinOSMInformation(conn, business_id, bin_number, materialized_view):\n",
    "    \"\"\"\n",
    "    Retrieves information from a materialized view related to OpenStreetMap (OSM).\n",
    "\n",
    "    Args:\n",
    "        conn (psycopg2.extensions.connection): Database connection.\n",
    "        business_id (str): ID of the central POI.\n",
    "        bin_number (int): Bin number.\n",
    "        materialized_view (str): Name of the materialized view.\n",
    "\n",
    "    Returns:\n",
    "        list: List of dictionaries containing information for the specified POI and bin.\n",
    "            Each dictionary includes relevant keys from the materialized view.\n",
    "    \"\"\"\n",
    "    result = None\n",
    "\n",
    "    sql = \"\"\"\n",
    "        SELECT *\n",
    "        FROM \"\"\"+materialized_view+\"\"\"\n",
    "        WHERE id = \\'\"\"\"+str(business_id)+\"\"\"\\' AND number = \"\"\"+str(bin_number)+\"\"\";\"\"\"\n",
    "\n",
    "    # print (sql)\n",
    "\n",
    "    result = executeQuery(conn, sql)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeoContext2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculateBinOSMPolygon_Disco(df, bin_number, mi=20):\n",
    "    \"\"\"\n",
    "    Generates binary relations between types of POIs and the polygonal geographic features. The binary relations are directly saved in the disco\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame containing POI information.\n",
    "        bin_number (int): related to context radius.\n",
    "        mi (int, optional): Value for mi. Defaults to 20.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    #Occurrence proportion (OP) and Space proportion (SP) weight\n",
    "    weights = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    radius = (1+bin_number)*100\n",
    "    print(\"executing radius:\", radius, \"m\")\n",
    "\n",
    "    # File to save directly to disk\n",
    "    writers = []\n",
    "    csv_files = []\n",
    "    for w in weights:\n",
    "        file_name = './geographic/GEOC2VECpiR/austin-sl-tuple-geoc2vec-' + str(bin_number) + 'bins_polygons_information-wgt' + str(w) + 'pfpe-c.csv'\n",
    "        csv_file = open(file_name, \"w\", newline='')\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        writer.writerow([\"poi_id_center\",\n",
    "                         \"center_poi\",\n",
    "                         \"center_poi_level\",\n",
    "                         \"context_osm\"])\n",
    "\n",
    "        csv_files.append(csv_file)\n",
    "        writers.append(writer)\n",
    "\n",
    "        # Creating communication channel with the database\n",
    "        try:\n",
    "            with SSHTunnelForwarder(\n",
    "                ('localhost', 22),\n",
    "                ssh_username=\"root\",\n",
    "                ssh_password=\"root\",\n",
    "                remote_bind_address=('localhost', 5432)\n",
    "            ) as server:\n",
    "                server.start()\n",
    "    \n",
    "                params = {'database': 'austin_test',\n",
    "                          'user': 'postgres',\n",
    "                          'password': 'root',\n",
    "                          'host': 'localhost',\n",
    "                          'port': server.local_bind_port\n",
    "                          }\n",
    "    \n",
    "                connection = psycopg2.connect(**params)\n",
    "    \n",
    "                for id_01, poi in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "                    # [business_id, checkin, category]\n",
    "                    poi_information = getPOIInformation(connection, poi['business_id'])\n",
    "                \n",
    "                    # [business_id, checkin, category, distance_m]\n",
    "                    if bin_number == 0:\n",
    "                        bin_osm_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'bins_polygons_information')\n",
    "                        bin_osm_building_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'bins_polygons_building_information')\n",
    "                    else:\n",
    "                        bin_osm_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'continuous_bins_polygons_information')\n",
    "                        bin_osm_building_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'continuous_bins_polygons_building_information')\n",
    "                \n",
    "                    # Calculating the two parameters below\n",
    "                    # oc - total number of different polygons in the bin\n",
    "                    oc = 0\n",
    "                    sc = 0\n",
    "                \n",
    "                    # If the bin contains any information\n",
    "                    if len(bin_osm_information) > 0:\n",
    "                        tags = list(dict(bin_osm_information[0]).keys())\n",
    "                        bin_osm_information = pd.DataFrame(bin_osm_information, columns=tags)\n",
    "                \n",
    "                        # Checking how many different polygon types exist\n",
    "                        oc = oc + bin_osm_information.iloc[:, 2:len(tags) - 4][~bin_osm_information.iloc[:, 2:len(tags) - 4].isin(['None'])].count().sum()\n",
    "                        sc = sc + (bin_osm_information.iloc[:,2:len(tags)-4][~bin_osm_information.iloc[:,2:len(tags)-3].isin(['None'])].count(axis=1)*bin_osm_information['way_area_in']).sum()\n",
    "                        \n",
    "                        #Excluding ids and bin_number\n",
    "                        tags = tags[2:len(tags)-4]\n",
    "\n",
    "                    # If the bin contains any information\n",
    "                    if len(bin_osm_building_information) > 0:\n",
    "                        tags_buildings = list(dict(bin_osm_building_information[0]).keys())\n",
    "                        bin_osm_building_information = pd.DataFrame(bin_osm_building_information, columns=tags_buildings)\n",
    "                    \n",
    "                        oc = oc + bin_osm_building_information.iloc[0]['building_count']\n",
    "                        sc = sc + bin_osm_building_information.iloc[0]['area_total']\n",
    "                    \n",
    "                        # Excluding IDs and bin_number\n",
    "                        tags_buildings = tags_buildings[1:2]\n",
    "                    \n",
    "                    # Additions are based on labels\n",
    "                    \n",
    "                    # Checking area completeness\n",
    "                    empty_area = -1\n",
    "                    if sc < area:\n",
    "                        oc += 1\n",
    "                        sc += area - sc\n",
    "                        empty_area = area - sc\n",
    "                    \n",
    "                    # To avoid division by zero\n",
    "                    if oc != 0:\n",
    "                        if (len(bin_osm_information) > 0):\n",
    "                            for tag in tags:\n",
    "                                \n",
    "                                #Iterate through each tag that indicates a geographic feature.\n",
    "                                geographic_features = set(bin_osm_information[tag].values)\n",
    "\n",
    "                                for feature in geographic_features:\n",
    "\n",
    "                                    if(feature != None):\n",
    "\n",
    "                                        #sf = all area o tag\n",
    "                                        #op = all occurences of tag \n",
    "                                        \n",
    "                                        sf = bin_osm_information[bin_osm_information[tag] == feature]['way_area_in'].sum()\n",
    "                                        of = bin_osm_information[bin_osm_information[tag] == feature][tag].count()\n",
    "\n",
    "                                        SP = math.ceil((sf/sc)*mi)        \n",
    "                                        OP = math.ceil((of/oc)*mi)\n",
    "                                        \n",
    "                                        for idx, w in enumerate(weights):\n",
    "                                            \n",
    "                                            aug = int(math.ceil((w*SP) + ((1 - w)*OP)))\n",
    "\n",
    "                                            if (aug <= 0):\n",
    "                                                aug = 1\n",
    "\n",
    "                                            name = \"polygons_\"+tag+\"_\"+feature\n",
    "\n",
    "                                            for center_poi in poi_information: # for each POI type tki\n",
    "                                                #Replicating binary relation <poi type, geographic feature>\n",
    "                                                for b in range(aug):\n",
    "\n",
    "                                                    line = [str(poi['business_id']), \n",
    "                                                            str(center_poi['name']),\n",
    "                                                            str(center_poi['level']),\n",
    "                                                            str(name)]\n",
    "                                                    writers[idx].writerow(line)\n",
    "\n",
    "                        #Calculating co-occurrence with polygons that are exclusively buildings.                   \n",
    "                        if (len(bin_osm_building_information) > 0):\n",
    "\n",
    "                            for id_02, row in bin_osm_building_information.iterrows():\n",
    "\n",
    "                                    #sf = all area o tag\n",
    "                                    #of = all occurences of tag\n",
    "\n",
    "                                    sf = row['area_total']\n",
    "                                    of = row['building_count']\n",
    "\n",
    "                                    SP = math.ceil((sf/sc)*mi)        \n",
    "                                    OP = math.ceil((of/oc)*mi)\n",
    "                                    \n",
    "                                    for idx, w in enumerate(weights):\n",
    "\n",
    "                                        aug = int(math.ceil((w*SP) + ((1 - w)*OP)))\n",
    "                                        if (aug <= 0):\n",
    "                                            aug = 1\n",
    "\n",
    "                                        name = 'polygons_building_yes'\n",
    "\n",
    "                                        for center_poi in poi_information: # for each POI type tki\n",
    "                                            #Replicating binary relation <poi type, geographic feature>\n",
    "                                            for b in range(aug):\n",
    "\n",
    "                                                line = [str(poi['business_id']), \n",
    "                                                        str(center_poi['name']),\n",
    "                                                        str(center_poi['level']),\n",
    "                                                        str(name)]\n",
    "                                                writers[idx].writerow(line)\n",
    "\n",
    "                            \n",
    "                for csv_file in csv_files:\n",
    "                    csv_file.close()\n",
    "                connection.close()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "def calculateBinOSMPolygon_distance_Disk(df, bin_number, mi = 20):\n",
    "\n",
    "    \"\"\"\n",
    "    Generates binary relations between types of POIs and the polygonal geographic features using distance to penalize the relations. \n",
    "    The binary relations are directly saved in the disk.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame containing POI information.\n",
    "        bin_number (int): related to context radius.\n",
    "        mi (int, optional): Value for mi. Defaults to 20.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    #Occurrence proportion (OP) and Space proportion (SP) weight\n",
    "    weights = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    radius = (1+bin_number)*100\n",
    "    \n",
    "    print(\"executing radius:\", radius, \"m\")\n",
    "\n",
    "    # File to save directly to disk\n",
    "    writers = []\n",
    "    csv_files = []\n",
    "    for w in weights:\n",
    "        \n",
    "    \n",
    "        file_name = './austin-sl-tuple-geoc2vec-' + str(bin_number) + 'bins_polygons_information-wgt'+str(w)+'pfp-c.csv'\n",
    "    \n",
    "    \n",
    "        csv_file = open(file_name, \"w\", newline='')\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        writer.writerow([\"poi_id_center\",\n",
    "                         \"center_poi\",\n",
    "                         \"center_poi_level\",\n",
    "                         \"context_osm\"])\n",
    "        \n",
    "        csv_files.append(csv_file)\n",
    "        writers.append(writer)\n",
    "\n",
    "    #Creating communication channel with postgres database\n",
    "    try:\n",
    "\n",
    "        with SSHTunnelForwarder(\n",
    "            ('localhost', 22),\n",
    "            ssh_username=\"root\",\n",
    "            ssh_password=\"root\", \n",
    "            remote_bind_address=('localhost', 5432)) as server:\n",
    "\n",
    "                server.start()\n",
    "\n",
    "                params = {'database': 'austin_test',\n",
    "                       'user': 'postgres',\n",
    "                       'password': 'root',\n",
    "                       'host': 'localhost',\n",
    "                       'port': server.local_bind_port\n",
    "                }\n",
    "\n",
    "                connection = psycopg2.connect(**params)\n",
    "\n",
    "                for id_01, poi in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "\n",
    "                    #[business_id, checkin, category]\n",
    "                    poi_information = getPOIInformation(connection, poi['business_id'])\n",
    "\n",
    "                    #[business_id, checkin, category, distance_m]\n",
    "                    if (bin_number == 0):\n",
    "                        bin_osm_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'bins_polygons_information')\n",
    "                        bin_osm_building_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'bins_polygons_building_information')\n",
    "\n",
    "                    else:\n",
    "                        bin_osm_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'continuous_bins_polygons_information')\n",
    "                        bin_osm_building_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'continuous_bins_polygons_building_information')\n",
    "\n",
    "\n",
    "                    #Calculating oc and sc from the algorithm\n",
    "                    oc = 0\n",
    "                    sc = 0\n",
    "\n",
    "                    #if the context contains some information\n",
    "                    if (len(bin_osm_information) > 0):\n",
    "                        tags = list(dict(bin_osm_information[0]).keys())\n",
    "                        bin_osm_information = pd.DataFrame(bin_osm_information, columns = tags)\n",
    "\n",
    "                        #Verifying how many geagraphif features (from polygons) exists\n",
    "                        oc = oc + bin_osm_information.iloc[:,2:len(tags)-4][~bin_osm_information.iloc[:,2:len(tags)-4].isin(['None'])].count().sum()\n",
    "                        \n",
    "                        sc = sc + (bin_osm_information.iloc[:,2:len(tags)-4][~bin_osm_information.iloc[:,2:len(tags)-3].isin(['None'])].count(axis=1)*bin_osm_information['way_area_in']).sum()\n",
    "                        \n",
    "                        #Excluding ids and bin_number\n",
    "                        tags = tags[2:len(tags)-4]\n",
    "\n",
    "                    #if the context contains some information (for building polygons)\n",
    "                    if (len(bin_osm_building_information) > 0):\n",
    "                        tags_buildings = list(dict(bin_osm_building_information[0]).keys())\n",
    "                        bin_osm_building_information = pd.DataFrame(bin_osm_building_information, columns = tags_buildings)\n",
    "\n",
    "                        oc = oc + bin_osm_building_information.iloc[0]['building_count']\n",
    "                        \n",
    "                        sc = sc + bin_osm_building_information.iloc[0]['area_total']\n",
    "\n",
    "                        #Excluding ids and bin_number\n",
    "                        tags_buildings = tags_buildings[1:2]\n",
    "\n",
    "                    #to avoid zero division\n",
    "                    if(oc != 0):\n",
    "                        if (len(bin_osm_information) > 0):\n",
    "                        \n",
    "                            for tag in tags:\n",
    "                                #Iterate over each geographic feature\n",
    "                                geographic_features = set(bin_osm_information[tag].values)\n",
    "\n",
    "                                for feature in geographic_features:\n",
    "\n",
    "                                    if(feature != None):\n",
    "\n",
    "                                        #sf = all area o tag\n",
    "                                        #op = all occurences of tag \n",
    "\n",
    "                                        sf = bin_osm_information[bin_osm_information[tag] == feature]['way_area_in'].sum()\n",
    "                                        of = bin_osm_information[bin_osm_information[tag] == feature][tag].count()\n",
    "                                        dst = bin_osm_information[bin_osm_information[tag] == feature]['distance_m'].mean()\n",
    "\n",
    "\n",
    "                                        SP = math.ceil((sf/sc)*mi)        \n",
    "                                        OP = math.ceil((of/oc)*mi)\n",
    "\n",
    "                                        for idx, w in enumerate(weights):\n",
    "\n",
    "                                            #Calculating relative distance\n",
    "                                            dst_rel = (dst/radius)\n",
    "                                            aug = int(math.ceil(((w*SP) + ((1 - w)*OP))/(1+dst_rel)))\n",
    "                                            if (aug <= 0):\n",
    "                                                aug = 1\n",
    "\n",
    "                                            name = \"polygons_\"+tag+\"_\"+feature\n",
    "\n",
    "                                            for center_poi in poi_information: # Para cada tki\n",
    "                                                #Replicating binary relations using aug information\n",
    "                                                for b in range(aug):\n",
    "\n",
    "                                                    line = [str(poi['business_id']), \n",
    "                                                            str(center_poi['name']),\n",
    "                                                            str(center_poi['level']),\n",
    "                                                            str(name)]\n",
    "                                                    writers[idx].writerow(line)\n",
    "\n",
    "                        #Calculating the co-occurence with polygons related to buidlings                    \n",
    "                        if (len(bin_osm_building_information) > 0):\n",
    "\n",
    "                            for id_02, row in bin_osm_building_information.iterrows(): \n",
    "\n",
    "                                #sf = all area o tag\n",
    "                                #of = all occurences of tag\n",
    "\n",
    "                                sf = row['area_total']\n",
    "                                of = row['building_count']\n",
    "                                \n",
    "                                if(bin_number == 0):\n",
    "                                    dst=50\n",
    "                                else:\n",
    "                                    dst = row['building_avg_distance']\n",
    "\n",
    "                                SP = math.ceil((sf/sc)*mi)        \n",
    "                                OP = math.ceil((of/oc)*mi)\n",
    "\n",
    "                                for idx, w in enumerate(weights):\n",
    "\n",
    "                                    dst_rel = (dst/radius)\n",
    "                                    aug = int(math.ceil(((w*SP) + ((1 - w)*OP))/(1+dst_rel)))\n",
    "                                    if (aug <= 0):\n",
    "                                        aug = 1\n",
    "\n",
    "                                    name = 'polygons_building_yes'\n",
    "\n",
    "                                    for center_poi in poi_information: # Para cada tki\n",
    "                                        #Aumentando-o pelo fator b\n",
    "                                        for b in range(aug):\n",
    "\n",
    "                                            line = [str(poi['business_id']), \n",
    "                                                    str(center_poi['name']),\n",
    "                                                    str(center_poi['level']),\n",
    "                                                    str(name)]\n",
    "                                            writers[idx].writerow(line)\n",
    "                        \n",
    "                            \n",
    "                for csv_file in csv_files:\n",
    "                    csv_file.close()\n",
    "                connection.close()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates binary relations between types of POIs and the polygonal geographic features using distance to penalize the relations.\n",
    "# The binary relations are directly saved in the disk.\n",
    "import csv\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculateBinOSMPolygon_pir_Disk(df, bin_number, mi=20):\n",
    "    \"\"\"\n",
    "    Generates binary relations between types of POIs and the polygonal geographic features using the circunference area (PiR²).\n",
    "    The binary relations are directly saved in the disk.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "        The DataFrame containing the data.\n",
    "    - bin_number: int\n",
    "        The bin number.\n",
    "    - mi: int, optional\n",
    "        The penalty factor (default is 20).\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    #Occurrence proportion (OP) and Space proportion (SP) weight\n",
    "    weights = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    radius = (1 + bin_number) * 100\n",
    "    area = math.pi * (radius * radius)\n",
    "    \n",
    "    print(\"executing radius:\", radius, \"m\")\n",
    "\n",
    "    # File to directly save to disk\n",
    "    writers = []\n",
    "    csv_files = []\n",
    "    for w in weights:\n",
    "        file_name = './austin-sl-tuple-geoc2vec-' + str(bin_number) + 'bins_polygons_information-wgt' + str(w) + 'pfp-c.csv'\n",
    "        csv_file = open(file_name, \"w\", newline='')\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        writer.writerow([\"poi_id_center\",\n",
    "                         \"center_poi\",\n",
    "                         \"center_poi_level\",\n",
    "                         \"context_osm\"])\n",
    "        csv_files.append(csv_file)\n",
    "        writers.append(writer)\n",
    "\n",
    "    # Creating communication channel with the database\n",
    "    try:\n",
    "        with SSHTunnelForwarder(\n",
    "            ('localhost', 22),\n",
    "            ssh_username=\"root\",\n",
    "            ssh_password=\"root\", \n",
    "            remote_bind_address=('localhost', 5432)) as server:\n",
    "\n",
    "            server.start()\n",
    "            params = {'database': 'austin_test',\n",
    "                      'user': 'postgres',\n",
    "                      'password': 'root',\n",
    "                      'host': 'localhost',\n",
    "                      'port': server.local_bind_port\n",
    "                      }\n",
    "\n",
    "            connection = psycopg2.connect(**params)\n",
    "\n",
    "            for id_01, poi in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "                poi_information = getPOIInformation(connection, poi['business_id'])\n",
    "\n",
    "                if bin_number == 0:\n",
    "                    bin_osm_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'bins_polygons_information')\n",
    "                    bin_osm_building_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'bins_polygons_building_information')\n",
    "                else:\n",
    "                    bin_osm_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'continuous_bins_polygons_information')\n",
    "                    bin_osm_building_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'continuous_bins_polygons_building_information')\n",
    "\n",
    "                oc = 0\n",
    "                if len(bin_osm_information) > 0:\n",
    "                    tags = list(dict(bin_osm_information[0]).keys())\n",
    "                    bin_osm_information = pd.DataFrame(bin_osm_information, columns=tags)\n",
    "                    oc += bin_osm_information.iloc[:, 2:len(tags)-4][~bin_osm_information.iloc[:, 2:len(tags)-4].isin(['None'])].count().sum()\n",
    "                    tags = tags[2:len(tags)-4]\n",
    "\n",
    "                if len(bin_osm_building_information) > 0:\n",
    "                    tags_buildings = list(dict(bin_osm_building_information[0]).keys())\n",
    "                    bin_osm_building_information = pd.DataFrame(bin_osm_building_information, columns=tags_buildings)\n",
    "                    oc += bin_osm_building_information.iloc[0]['building_count']\n",
    "                    tags_buildings = tags_buildings[1:2]\n",
    "\n",
    "                if oc != 0:\n",
    "                    if len(bin_osm_information) > 0:\n",
    "                        for tag in tags:\n",
    "                            geographic_features = set(bin_osm_information[tag].values)\n",
    "                            for feature in geographic_features:\n",
    "                                if feature is not None:\n",
    "                                    sf = bin_osm_information[bin_osm_information[tag] == feature]['way_area_in'].sum()\n",
    "                                    of = bin_osm_information[bin_osm_information[tag] == feature][tag].count()\n",
    "                                    SP = math.ceil((sf / area) * mi)        \n",
    "                                    OP = math.ceil((of / oc) * mi)\n",
    "                                    for idx, w in enumerate(weights):\n",
    "                                        aug = int(math.ceil((w * SP) + ((1 - w) * OP)))\n",
    "                                        if aug <= 0:\n",
    "                                            aug = 1\n",
    "                                        name = \"polygons_\" + tag + \"_\" + feature\n",
    "                                        for center_poi in poi_information:\n",
    "                                            for b in range(aug):\n",
    "                                                line = [str(poi['business_id']), \n",
    "                                                        str(center_poi['name']),\n",
    "                                                        str(center_poi['level']),\n",
    "                                                        str(name)]\n",
    "                                                writers[idx].writerow(line)\n",
    "\n",
    "                    if len(bin_osm_building_information) > 0:\n",
    "                        for id_02, row in bin_osm_building_information.iterrows():\n",
    "                            sf = row['area_total']\n",
    "                            of = row['building_count']\n",
    "                            SP = math.ceil((sf / area) * mi)        \n",
    "                            OP = math.ceil((of / oc) * mi)\n",
    "                            for idx, w in enumerate(weights):\n",
    "                                aug = int(math.ceil((w * SP) + ((1 - w) * OP)))\n",
    "                                if aug <= 0:\n",
    "                                    aug = 1\n",
    "                                name = 'polygons_building_yes'\n",
    "                                for center_poi in poi_information:\n",
    "                                    for b in range(aug):\n",
    "                                        line = [str(poi['business_id']), \n",
    "                                                str(center_poi['name']),\n",
    "                                                str(center_poi['level']),\n",
    "                                                str(name)]\n",
    "                                        writers[idx].writerow(line)\n",
    "\n",
    "        for csv_file in csv_files:\n",
    "            csv_file.close()\n",
    "        connection.close()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "def calculateBinOSMRoadsLines_Disk(df, bin_number, mi=20, roads=True):\n",
    "    \"\"\"\n",
    "    Generates binary relations between types of POIs and the linear geographic features.\n",
    "    The binary relations are directly saved in the disk.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "        The DataFrame containing the data.\n",
    "    - bin_number: int\n",
    "        The bin number.\n",
    "    - mi: int, optional\n",
    "        The penalty factor (default is 20).\n",
    "    - roads: bool, optional\n",
    "        Flag indicating whether to process roads or lines (default is True).\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Occurrence proportion (OP) and Space proportion (SP) weight\n",
    "    weights = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    radius = (1 + bin_number) * 100\n",
    "    \n",
    "    if roads:\n",
    "        t_name = 'bins_roads_information'\n",
    "        table = \"roads\"\n",
    "        if bin_number == 0:\n",
    "            materialized_view = 'bins_roads_information'\n",
    "        else:\n",
    "            materialized_view = 'continuous_bins_roads_information'\n",
    "    else:\n",
    "        t_name = 'bins_lines_information'\n",
    "        table = \"lines\"\n",
    "        if bin_number == 0:\n",
    "            materialized_view = 'bins_lines_information'\n",
    "        else:\n",
    "            materialized_view = 'continuous_bins_lines_information'\n",
    "\n",
    "    print(\"executing radius:\", radius, \"m\")\n",
    "\n",
    "    # Creating files to save directly on the disk\n",
    "    writers = []\n",
    "    csv_files = []\n",
    "    for w in weights:\n",
    "        file_name = './austin-sl-tuple-geoc2vec-' + str(bin_number) + t_name + '-wgt'+str(w)+'pfp-c.csv'\n",
    "        csv_file = open(file_name, \"w\", newline='')\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        writer.writerow([\"poi_id_center\",\n",
    "                          \"center_poi\",\n",
    "                          \"center_poi_level\",\n",
    "                          \"context_osm\"])\n",
    "        csv_files.append(csv_file)\n",
    "        writers.append(writer)\n",
    "\n",
    "    # Creating communication channel with the database\n",
    "    try:\n",
    "        with SSHTunnelForwarder(\n",
    "            ('localhost', 22),\n",
    "            ssh_username=\"root\",\n",
    "            ssh_password=\"root\", \n",
    "            remote_bind_address=('localhost', 5432)) as server:\n",
    "\n",
    "            server.start()\n",
    "            params = {'database': 'austin_test',\n",
    "                      'user': 'postgres',\n",
    "                      'password': 'root',\n",
    "                      'host': 'localhost',\n",
    "                      'port': server.local_bind_port}\n",
    "\n",
    "            connection = psycopg2.connect(**params)\n",
    "\n",
    "            for id_01, poi in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "                poi_information = getPOIInformation(connection, poi['business_id'])\n",
    "                bin_osm_information = getBinOSMInformation(connection, poi['business_id'], bin_number, materialized_view)\n",
    "\n",
    "                if len(bin_osm_information) > 0:\n",
    "                    tags = list(dict(bin_osm_information[0]).keys())\n",
    "                    bin_osm_information = pd.DataFrame(bin_osm_information, columns=tags)\n",
    "\n",
    "                    oc = bin_osm_information.iloc[:, 2:len(tags)-3][~bin_osm_information.iloc[:, 2:len(tags)-3].isin(['None'])].count().sum()\n",
    "                    sc = (bin_osm_information.iloc[:, 2:len(tags)-3][~bin_osm_information.iloc[:, 2:len(tags)-3].isin(['None'])].count(axis=1) * bin_osm_information['length']).sum()\n",
    "\n",
    "                    tags = tags[2:len(tags)-3]\n",
    "\n",
    "                    if oc != 0:\n",
    "                        for tag in tags:\n",
    "                            geographic_features = set(bin_osm_information[tag].values)\n",
    "                            for feature in geographic_features:\n",
    "                                if feature is not None:\n",
    "                                    \n",
    "                                    sf = bin_osm_information[bin_osm_information[tag] == feature]['length'].sum()\n",
    "                                    of = bin_osm_information[bin_osm_information[tag] == feature][tag].count()\n",
    "\n",
    "                                    SP = math.ceil((sf / sc) * mi)        \n",
    "                                    OP = math.ceil((of / oc) * mi)\n",
    "                                    \n",
    "                                    for idx, w in enumerate(weights):\n",
    "                                        aug = int(math.ceil((w * SP) + ((1 - w) * OP)))\n",
    "                                        if aug <= 0:\n",
    "                                            aug = 1\n",
    "                                        name = table + \"_\" + tag + \"_\" + feature\n",
    "                                        for center_poi in poi_information: \n",
    "                                            for b in range(aug):\n",
    "                                                line = [str(poi['business_id']), \n",
    "                                                        str(center_poi['name']),\n",
    "                                                        str(center_poi['level']),\n",
    "                                                        str(name)]\n",
    "                                                writers[idx].writerow(line)\n",
    "\n",
    "            for csv_file in csv_files:\n",
    "                csv_file.close()\n",
    "            connection.close()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "def calculateBinOSMRoadsLines_distance_Disk(df, bin_number, mi=220, roads=True, w=0.5):\n",
    "    \"\"\"\n",
    "    Generates binary relations between types of POIs and the linear geographic features using distance to penalize the relations.\n",
    "    The binary relations are saved directly to the disk.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "        The DataFrame containing the data.\n",
    "    - bin_number: int\n",
    "        The bin number.\n",
    "    - mi: int, optional\n",
    "        The penalty factor (default is 20).\n",
    "    - roads: bool, optional\n",
    "        Flag indicating whether to process roads or lines (default is True).\n",
    "    - w: float, optional\n",
    "        Weight factor for balancing SP and OP (default is 0.5).\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Occurrence proportion (OP) and Space proportion (SP) weight\n",
    "    weights = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    radius = (1 + bin_number) * 100\n",
    "    \n",
    "    w = round(w, 1)\n",
    "    \n",
    "    if roads:\n",
    "        t_name = 'bins_roads_information'\n",
    "        table = \"roads\"\n",
    "        if (bin_number == 0):\n",
    "            materialized_view = 'bins_roads_information'\n",
    "        else:\n",
    "            materialized_view = 'continuous_bins_roads_information'\n",
    "    else:\n",
    "        t_name = 'bins_lines_information'\n",
    "        table = \"lines\"\n",
    "        if(bin_number == 0):\n",
    "            materialized_view = 'bins_lines_information'\n",
    "        else:\n",
    "            materialized_view = 'continuous_bins_lines_information'\n",
    "\n",
    "    print(\"executing radius:\", radius, \"m\")\n",
    "\n",
    "    # Creating files to save directly on the disk\n",
    "    writers = []\n",
    "    csv_files = []\n",
    "    for w in weights:\n",
    "        file_name = './austin-sl-tuple-geoc2vec-' + str(bin_number) + t_name + '-wgt'+str(w)+'pfp-c.csv'\n",
    "        csv_file = open(file_name, \"w\", newline='')\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        writer.writerow([\"poi_id_center\",\n",
    "                          \"center_poi\",\n",
    "                          \"center_poi_level\",\n",
    "                          \"context_osm\"])\n",
    "        csv_files.append(csv_file)\n",
    "        writers.append(writer)\n",
    "\n",
    "    # Creating communication channel with the database\n",
    "    try:\n",
    "        with SSHTunnelForwarder(\n",
    "            ('localhost', 23456),\n",
    "            #ssh_private_key=\"</path/to/private/ssh/key>\",\n",
    "            ### in my case, I used a password instead of a private key\n",
    "            ssh_username=\"root\",\n",
    "            ssh_password=\"root\", \n",
    "            remote_bind_address=('localhost', 5432)) as server:\n",
    "\n",
    "                server.start()\n",
    "                #print(\"server connected\")\n",
    "\n",
    "                params = {'database': 'austin_test',\n",
    "                       'user': 'postgres',\n",
    "                       'password': 'root',\n",
    "                       'host': 'localhost',\n",
    "                       'port': server.local_bind_port\n",
    "                }\n",
    "\n",
    "                connection = psycopg2.connect(**params)\n",
    "\n",
    "                for id_01, poi in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "\n",
    "                    #[business_id, checkin, category]\n",
    "                    poi_information = getPOIInformation(connection, poi['business_id'])\n",
    "\n",
    "\n",
    "                    #[business_id, checkin, category, distance_m]\n",
    "                    bin_osm_information = getBinOSMInformation(connection, poi['business_id'], bin_number, materialized_view)\n",
    "\n",
    "                    # If the bin is filled with some information\n",
    "                    if (len(bin_osm_information) > 0):\n",
    "                        tags = list(dict(bin_osm_information[0]).keys())\n",
    "\n",
    "                        bin_osm_information = pd.DataFrame(bin_osm_information, columns = tags)\n",
    "\n",
    "                        # Calculating the two parameters below\n",
    "                        # oc - total number of roads/lines in the bin\n",
    "                        oc = bin_osm_information.iloc[:,2:len(tags)-3][~bin_osm_information.iloc[:,2:len(tags)-3].isin(['None'])].count().sum()\n",
    "\n",
    "                        # sc - total length of each type of roads/lines in the bin\n",
    "                        sc = (bin_osm_information.iloc[:,2:len(tags)-3][~bin_osm_information.iloc[:,2:len(tags)-3].isin(['None'])].count(axis=1)*bin_osm_information['length']).sum()\n",
    "\n",
    "\n",
    "                        # Excluding ids and bin_number\n",
    "                        tags = tags[2:len(tags)-3]\n",
    "\n",
    "                        # The additions are made based on the labels\n",
    "                        # To avoid division by zero\n",
    "                        if(oc != 0):\n",
    "                            for tag in tags:\n",
    "                                # Iterating through each tag\n",
    "                                geographic_features = set(bin_osm_information[tag].values)\n",
    "\n",
    "                                for feature in geographic_features:\n",
    "\n",
    "                                    if(feature != None):\n",
    "\n",
    "                                        # sp = all length of the tag\n",
    "                                        # op = all occurrences of the tag\n",
    "                                        sf = bin_osm_information[bin_osm_information[tag] == feature]['length'].sum()\n",
    "                                        of = bin_osm_information[bin_osm_information[tag] == feature][tag].count()\n",
    "                                        dst = bin_osm_information[bin_osm_information[tag] == feature]['distance_m'].mean()\n",
    "\n",
    "                                        SP = math.ceil((sf/sc)*mi)        \n",
    "                                        OP = math.ceil((of/oc)*mi)\n",
    "                                        \n",
    "                                        dst_rel = (dst/radius)\n",
    "\n",
    "                                        for idx, w in enumerate(weights):\n",
    "                                            \n",
    "                                            aug = int(math.ceil(((w*SP) + ((1 - w)*OP))/(1+dst_rel)))\n",
    "                                            if (aug <= 0):\n",
    "                                                aug = 1\n",
    "\n",
    "                                            name = table+\"_\"+tag+\"_\"+feature\n",
    "\n",
    "                                            for center_poi in poi_information: # For each tki\n",
    "                                                # Increasing it by the factor b\n",
    "                                                for b in range(aug):\n",
    "                                                    line = [str(poi['business_id']), \n",
    "                                                            str(center_poi['name']),\n",
    "                                                            str(center_poi['level']),\n",
    "                                                            str(name)]\n",
    "                                                    writers[idx].writerow(line)\n",
    "\n",
    "                                \n",
    "                for csv_file in csv_files:\n",
    "                    csv_file.close()\n",
    "                connection.close()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        #print(\"Connection Failed\")\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "def calculateBinOSMRoadsLines_Estimated_Disk(df, bin_number, mi=20, roads=True):\n",
    "    \"\"\"\n",
    "    Generates binary relations between types of POIs and the linear geographic features using estimated values for lines/roads lengths.\n",
    "    The binary relations are saved directly to the disk.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "        The DataFrame containing the data.\n",
    "    - bin_number: int\n",
    "        The bin number.\n",
    "    - mi: int, optional\n",
    "        The penalty factor (default is 20).\n",
    "    - roads: bool, optional\n",
    "        Flag indicating whether to process roads or lines (default is True).\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    radius = (1 + bin_number) * 100\n",
    "\n",
    "    # Estimated lengths for bins\n",
    "    lines_values = [738, 1682, 2668, 3297, 4022, 4481, 4984, 6375, 7538]\n",
    "    roads_values = [347, 699, 1180, 1593, 2010, 2010, 2011, 2435, 2687]\n",
    "\n",
    "    if roads:\n",
    "        c = roads_values[bin_number]\n",
    "        t_name = 'bins_roads_information'\n",
    "        table = \"roads\"\n",
    "        if bin_number == 0:\n",
    "            materialized_view = 'bins_roads_information'\n",
    "        else:\n",
    "            materialized_view = 'continuous_bins_roads_information'\n",
    "    else:\n",
    "        c = lines_values[bin_number]\n",
    "        t_name = 'bins_lines_information'\n",
    "        table = \"lines\"\n",
    "        if bin_number == 0:\n",
    "            materialized_view = 'bins_lines_information'\n",
    "        else:\n",
    "            materialized_view = 'continuous_bins_lines_information'\n",
    "\n",
    "    print(\"executing radius:\", radius, \"m\")\n",
    "    # Occurrence proportion (OP) and Space proportion (SP) weight\n",
    "    weights = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "    # Creating files to save directly on the disk\n",
    "    writers = []\n",
    "    csv_files = []\n",
    "    for w in weights:\n",
    "        file_name = './geographic/GEOC2VEC COMP 2/austin-sl-tuple-geoc2vec-' + str(bin_number) + t_name + '-wgt'+str(w)+'pfp-c.csv'\n",
    "        csv_file = open(file_name, \"w\", newline='')\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        writer.writerow([\"poi_id_center\",\n",
    "                          \"center_poi\",\n",
    "                          \"center_poi_level\",\n",
    "                          \"context_osm\"])\n",
    "        csv_files.append(csv_file)\n",
    "        writers.append(writer)\n",
    "\n",
    "    with SSHTunnelForwarder(\n",
    "        ('localhost', 23456),\n",
    "        ssh_username=\"root\",\n",
    "        ssh_password=\"root\", \n",
    "        remote_bind_address=('localhost', 5432)) as server:\n",
    "\n",
    "            server.start()\n",
    "\n",
    "            params = {'database': 'austin_test',\n",
    "                      'user': 'postgres',\n",
    "                      'password': 'root',\n",
    "                      'host': 'localhost',\n",
    "                      'port': server.local_bind_port}\n",
    "\n",
    "            connection = psycopg2.connect(**params)\n",
    "\n",
    "            for id_01, poi in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "\n",
    "                poi_information = getPOIInformation(connection, poi['business_id'])\n",
    "                bin_osm_information = getBinOSMInformation(connection, poi['business_id'], bin_number, materialized_view)\n",
    "\n",
    "                # If the bin is filled with some information\n",
    "                if len(bin_osm_information) > 0:\n",
    "                    tags = list(dict(bin_osm_information[0]).keys())\n",
    "                    bin_osm_information = pd.DataFrame(bin_osm_information, columns=tags)\n",
    "\n",
    "                    # Calculating the two parameters below\n",
    "                    # oc - total number of roads/lines in the bin\n",
    "                    oc = bin_osm_information.iloc[:, 2:len(tags)-3][~bin_osm_information.iloc[:, 2:len(tags)-3].isin(['None'])].count().sum()\n",
    "\n",
    "                    # Excluding ids and bin_number\n",
    "                    tags = tags[2:len(tags)-3]\n",
    "\n",
    "                    # Adding based on the labels\n",
    "                    # To avoid division by zero\n",
    "                    if oc != 0:\n",
    "                        for tag in tags:\n",
    "                            # Iterating through each tag\n",
    "                            geographic_features = set(bin_osm_information[tag].values)\n",
    "\n",
    "                            for feature in geographic_features:\n",
    "\n",
    "                                if feature is not None:\n",
    "\n",
    "                                    # sp = all length of the tag\n",
    "                                    # op = all occurrences of the tag\n",
    "                                    sf = bin_osm_information[bin_osm_information[tag] == feature]['length'].sum()\n",
    "                                    of = bin_osm_information[bin_osm_information[tag] == feature][tag].count()\n",
    "\n",
    "                                    # Proportion considering the circumference\n",
    "                                    SP = math.ceil((sf/c)*mi)\n",
    "                                    OP = math.ceil((of/oc)*mi)\n",
    "\n",
    "                                    name = table + \"_\" + tag + \"_\" + feature\n",
    "\n",
    "                                    for idx, w in enumerate(weights):\n",
    "\n",
    "                                        aug = int(math.ceil((w*SP) + ((1 - w)*OP)))\n",
    "\n",
    "                                        if aug <= 0:\n",
    "                                            aug = 1\n",
    "\n",
    "                                        for center_poi in poi_information: # For each tki\n",
    "                                            # Increasing it by the factor b\n",
    "                                            for b in range(aug):\n",
    "                                                line = [str(poi['business_id']), \n",
    "                                                        str(center_poi['name']),\n",
    "                                                        str(center_poi['level']),\n",
    "                                                        str(name)]\n",
    "                                                writers[idx].writerow(line)\n",
    "\n",
    "            for csv_file in csv_files:\n",
    "                csv_file.close()\n",
    "            connection.close()\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "def calculateBinOSMPoints_Disk(df, bin_number, mi=20):\n",
    "    \"\"\"\n",
    "    Generates binary relations between types of POIs and the geographic points inside bins.\n",
    "    The binary relations are saved directly to the disk.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "        The DataFrame containing the data.\n",
    "    - bin_number: int\n",
    "        The bin number.\n",
    "    - mi: int, optional\n",
    "        The penalty factor (default is 20).\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    radius = (1 + bin_number) * 100\n",
    "    print(\"executing radius:\", radius)\n",
    "\n",
    "    # File to save directly to disk\n",
    "    file_name = './austin-sl-tuple-geoc2vec-' + str(bin_number) + 'bins_points_information-pfp-c.csv'\n",
    "    \n",
    "    csv_file = open(file_name, \"w\", newline='')\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    writer.writerow([\"poi_id_center\",\n",
    "                     \"center_poi\",\n",
    "                     \"center_poi_level\",\n",
    "                     \"context_osm\"])\n",
    "\n",
    "    # Creating communication channel with the database\n",
    "    connection = connect()  \n",
    "\n",
    "    if connection:\n",
    "\n",
    "        for id_01, poi in df.iterrows():\n",
    "            \n",
    "            poi_information = getPOIInformation(connection, poi['business_id'])\n",
    "\n",
    "            if bin_number == 0:\n",
    "                bin_osm_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'bins_points_information')\n",
    "            else:\n",
    "                bin_osm_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'continuous_bins_points_information')\n",
    "\n",
    "            \n",
    "            # If the bin is filled with some information\n",
    "            if len(bin_osm_information) > 0:\n",
    "\n",
    "                tags = list(dict(bin_osm_information[0]).keys())\n",
    "                bin_osm_information = pd.DataFrame(bin_osm_information, columns=tags)\n",
    "\n",
    "            \n",
    "                # oc - total number of different types of points in the bin\n",
    "                oc = bin_osm_information.iloc[:, 2:len(tags)-2][~bin_osm_information.iloc[:, 2:len(tags)-2].isin(['None'])].count().sum()\n",
    "                \n",
    "                # Excluding ids and bin_number\n",
    "                tags = tags[2:len(tags)-2]\n",
    "                \n",
    "                # Adding based on the labels\n",
    "\n",
    "                # To avoid division by zero\n",
    "                if oc != 0:\n",
    "\n",
    "                    for tag in tags:\n",
    "                        # Iterating through each tag\n",
    "                        geographic_features = set(bin_osm_information[tag].values)\n",
    "                        \n",
    "                        for feature in geographic_features:\n",
    "                            \n",
    "                            if feature is not None:\n",
    "                                \n",
    "                                of = bin_osm_information[bin_osm_information[tag] == feature][tag].count()\n",
    "                                \n",
    "                                OP = (of/oc)*mi\n",
    "                                \n",
    "                                aug = math.ceil(OP)\n",
    "                                if aug <= 0:\n",
    "                                    aug = 1\n",
    "                                \n",
    "                                name = \"points_\"+tag+\"_\"+feature\n",
    "\n",
    "\n",
    "                                for center_poi in poi_information: # For each tki\n",
    "                                    # Increasing it by the factor b\n",
    "                                    for b in range(aug):\n",
    "\n",
    "                                        line = [str(poi['business_id']), \n",
    "                                                str(center_poi['name']),\n",
    "                                                str(center_poi['level']),\n",
    "                                                str(name)]\n",
    "                                        writer.writerow(line)\n",
    "        \n",
    "        csv_file.close()\n",
    "        closeConnection(connection)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "def calculateBinOSMPoints_distance_Disk(df, bin_number, mi=20):\n",
    "    \"\"\"\n",
    "    Generates binary relations between types of POIs and the geographic points inside bins,\n",
    "    taking into account the distance factor. The binary relations are saved directly to the disk.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "        The DataFrame containing the data.\n",
    "    - bin_number: int\n",
    "        The bin number.\n",
    "    - mi: int, optional\n",
    "        The penalty factor (default is 20).\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    radius = (1 + bin_number) * 100\n",
    "    print(\"executing radius:\", radius)\n",
    "\n",
    "    # File to save directly to disk\n",
    "    file_name = './austin-sl-tuple-geoc2vec-' + str(bin_number) + 'bins_points_information-pfp-c.csv'\n",
    "    \n",
    "    csv_file = open(file_name, \"w\", newline='')\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    writer.writerow([\"poi_id_center\",\n",
    "                     \"center_poi\",\n",
    "                     \"center_poi_level\",\n",
    "                     \"context_osm\"])\n",
    "\n",
    "    # Creating communication channel with the database\n",
    "    try:\n",
    "\n",
    "        with SSHTunnelForwarder(\n",
    "            ('localhost', 23456),\n",
    "            ssh_username=\"root\",\n",
    "            ssh_password=\"root\", \n",
    "            remote_bind_address=('localhost', 5432)) as server:\n",
    "\n",
    "                server.start()\n",
    "\n",
    "                params = {'database': 'austin_test',\n",
    "                       'user': 'postgres',\n",
    "                       'password': 'root',\n",
    "                       'host': 'localhost',\n",
    "                       'port': server.local_bind_port\n",
    "                }\n",
    "\n",
    "                connection = psycopg2.connect(**params)\n",
    "\n",
    "                for id_01, poi in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "\n",
    "                    poi_information = getPOIInformation(connection, poi['business_id'])\n",
    "\n",
    "                    if bin_number == 0:\n",
    "                        bin_osm_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'bins_points_information')\n",
    "                    else:\n",
    "                        bin_osm_information = getBinOSMInformation(connection, poi['business_id'], bin_number, 'continuous_bins_points_information')\n",
    "\n",
    "\n",
    "                    if len(bin_osm_information) > 0:\n",
    "\n",
    "                        tags = list(dict(bin_osm_information[0]).keys())\n",
    "                        bin_osm_information = pd.DataFrame(bin_osm_information, columns=tags)\n",
    "\n",
    "                        oc = bin_osm_information.iloc[:, 2:len(tags)-2][~bin_osm_information.iloc[:, 2:len(tags)-2].isin(['None'])].count().sum()\n",
    "\n",
    "                        tags = tags[2:len(tags)-2]\n",
    "\n",
    "                        if oc != 0:\n",
    "\n",
    "                            for tag in tags:\n",
    "                                geographic_features = set(bin_osm_information[tag].values)\n",
    "\n",
    "                                for feature in geographic_features:\n",
    "\n",
    "                                    if feature is not None:\n",
    "\n",
    "                                        of = bin_osm_information[bin_osm_information[tag] == feature][tag].count()\n",
    "                                        dst = bin_osm_information[bin_osm_information[tag] == feature]['distance_m'].mean()\n",
    "                                        OP = (of/oc)*mi\n",
    "                                        \n",
    "                                        dst_rel = (dst/radius)\n",
    "\n",
    "                                        aug = math.ceil(OP/(1+dst_rel))\n",
    "                                        \n",
    "                                        if aug <= 0:\n",
    "                                            aug = 1\n",
    "                                            \n",
    "\n",
    "                                        name = \"points_\"+tag+\"_\"+feature\n",
    "\n",
    "                                        for center_poi in poi_information: \n",
    "                                            for b in range(aug):\n",
    "\n",
    "                                                line = [str(poi['business_id']), \n",
    "                                                        str(center_poi['name']),\n",
    "                                                        str(center_poi['level']),\n",
    "                                                        str(name)]\n",
    "                                                writer.writerow(line)\n",
    "\n",
    "            \n",
    "                connection.close()\n",
    "        \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    csv_file.close()\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22399, 7)\n",
      "(22399, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>categories</th>\n",
       "      <th>checkin_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N3_Gs3DnX4k9SgpwJxdEfw</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>30.346169</td>\n",
       "      <td>-97.711458</td>\n",
       "      <td>Shopping, Jewelry Repair, Appraisal Services, ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tXvdYGvlEceDljN8gt2_3Q</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>30.172706</td>\n",
       "      <td>-97.799920</td>\n",
       "      <td>Barbers, Beauty &amp; Spas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nTIhpR7MhsALPwg_Hh14EA</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>30.326377</td>\n",
       "      <td>-97.704543</td>\n",
       "      <td>Hotels, Hotels &amp; Travel, Event Planning &amp; Serv...</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8XyEpVdAO0o6iVkVxkWosQ</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>30.246465</td>\n",
       "      <td>-97.778738</td>\n",
       "      <td>Home Services, Real Estate, Property Management</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NVfOn7TdnHbaGH97CVB_Qg</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>30.244902</td>\n",
       "      <td>-97.857409</td>\n",
       "      <td>Chiropractors, Health &amp; Medical</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id    city state   latitude  longitude  \\\n",
       "0  N3_Gs3DnX4k9SgpwJxdEfw  Austin    TX  30.346169 -97.711458   \n",
       "1  tXvdYGvlEceDljN8gt2_3Q  Austin    TX  30.172706 -97.799920   \n",
       "2  nTIhpR7MhsALPwg_Hh14EA  Austin    TX  30.326377 -97.704543   \n",
       "3  8XyEpVdAO0o6iVkVxkWosQ  Austin    TX  30.246465 -97.778738   \n",
       "4  NVfOn7TdnHbaGH97CVB_Qg  Austin    TX  30.244902 -97.857409   \n",
       "\n",
       "                                          categories  checkin_count  \n",
       "0  Shopping, Jewelry Repair, Appraisal Services, ...             14  \n",
       "1                             Barbers, Beauty & Spas              1  \n",
       "2  Hotels, Hotels & Travel, Event Planning & Serv...            475  \n",
       "3    Home Services, Real Estate, Property Management              0  \n",
       "4                    Chiropractors, Health & Medical             33  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pois_file_name = './austin-ml-updated.csv'\n",
    "df = pd.read_csv(pois_file_name)\n",
    "print(df.shape)\n",
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteractive Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execution of functions that generate the training set for GeoContext2Vec using relative space proportions.\n",
    "for bin_number in range(0, 2):\n",
    "    calculateBinOSMPolygon_Disco(df, bin_number)\n",
    "    calculateBinOSMRoadsLines_Disco(df, bin_number, roads=False)\n",
    "    calculateBinOSMRoadsLines_Disco(df, bin_number, roads=True)\n",
    "    calculateBinOSMPoints_Disco(df, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execution of functions that generate the training set for GeoContext2Vec using absolute space proportions.\n",
    "for bin_number in range(0, 2):\n",
    "    calculateBinOSMPolygon_pir_Disk(df, bin_number)\n",
    "    calculateBinOSMRoadsLines_Estimated_Disk(df, bin_number, roads=False)\n",
    "    calculateBinOSMRoadsLines_Estimated_Disk(df, bin_number, roads=True)\n",
    "    calculateBinOSMPoints_Disco(df, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Execution Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processors:  20\n",
      "executing radius: 100 m\n",
      "executing radius: 200 m\n",
      "executing radius: 300 m\n",
      "executing radius: 400 m\n",
      "executing radius: 500 m\n",
      "executing radius: 600 m\n",
      "executing radius: 700 m\n",
      "executing radius: 800 m\n",
      "executing radius: 900 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22399/22399 [17:39<00:00, 21.14it/s]\n",
      "100%|██████████| 22399/22399 [20:21<00:00, 18.34it/s]\n",
      "100%|██████████| 22399/22399 [22:15<00:00, 16.77it/s]\n",
      "100%|██████████| 22399/22399 [23:42<00:00, 15.74it/s]\n",
      "100%|██████████| 22399/22399 [24:59<00:00, 14.94it/s]\n",
      "100%|██████████| 22399/22399 [26:17<00:00, 14.20it/s]\n",
      "100%|██████████| 22399/22399 [27:32<00:00, 13.56it/s]\n",
      "100%|██████████| 22399/22399 [28:47<00:00, 12.97it/s]\n",
      "100%|██████████| 22399/22399 [30:12<00:00, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing radius: 300 m\n",
      "executing radius: 400 m\n",
      "executing radius: 500 m\n",
      "executing radius: 100 m\n",
      "executing radius: 600 m\n",
      "executing radius: 700 m\n",
      "executing radius: 200 m\n",
      "executing radius: 800 m\n",
      "executing radius: 900 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22399/22399 [10:06<00:00, 36.91it/s]\n",
      "100%|██████████| 22399/22399 [14:39<00:00, 25.48it/s]\n",
      " 82%|████████▏ | 18399/22399 [16:42<03:43, 17.86it/s]\n",
      "100%|██████████| 22399/22399 [18:13<00:00, 20.47it/s]\n",
      "100%|██████████| 22399/22399 [19:08<00:00, 19.50it/s]\n",
      "100%|██████████| 22399/22399 [19:49<00:00, 18.84it/s]\n",
      "100%|██████████| 22399/22399 [20:19<00:00, 18.37it/s]\n",
      "100%|██████████| 22399/22399 [20:44<00:00, 18.00it/s]\n",
      "100%|██████████| 22399/22399 [21:04<00:00, 17.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing radius: 100 m\n",
      "executing radius: 200 m\n",
      "executing radius: 300 m\n",
      "executing radius: 400 m\n",
      "executing radius: 500 m\n",
      "executing radius: 600 m\n",
      "executing radius: 700 m\n",
      "executing radius: 800 m\n",
      "executing radius: 900 m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22399/22399 [22:29<00:00, 16.59it/s] \n",
      "100%|██████████| 22399/22399 [24:24<00:00, 15.30it/s]\n",
      "100%|██████████| 22399/22399 [26:12<00:00, 14.25it/s]\n",
      "100%|██████████| 22399/22399 [27:58<00:00, 13.34it/s]\n",
      "100%|██████████| 22399/22399 [29:40<00:00, 12.58it/s]\n",
      "100%|██████████| 22399/22399 [31:36<00:00, 11.81it/s]\n",
      "100%|██████████| 22399/22399 [33:35<00:00, 11.11it/s]\n",
      "100%|██████████| 22399/22399 [35:46<00:00, 10.44it/s]\n",
      "100%|██████████| 22399/22399 [37:55<00:00,  9.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing radius: 100\n",
      "executing radius: 200\n",
      "executing radius: 300\n",
      "executing radius: 400\n",
      "executing radius: 500\n",
      "executing radius: 600\n",
      "executing radius: 700\n",
      "executing radius: 800\n",
      "executing radius: 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22399/22399 [09:59<00:00, 37.37it/s]\n",
      "100%|██████████| 22399/22399 [16:30<00:00, 22.61it/s]\n",
      " 85%|████████▍ | 19001/22399 [17:55<03:08, 18.06it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 22399/22399 [20:13<00:00, 18.46it/s]\n",
      "100%|██████████| 22399/22399 [21:07<00:00, 17.67it/s]\n",
      "100%|██████████| 22399/22399 [21:54<00:00, 17.04it/s]\n",
      "100%|██████████| 22399/22399 [22:44<00:00, 16.41it/s]\n",
      "100%|██████████| 22399/22399 [23:29<00:00, 15.89it/s]\n",
      "100%|██████████| 22399/22399 [24:21<00:00, 15.33it/s]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "print(\"Number of processors: \", mp.cpu_count())\n",
    "\n",
    "# Step 1: Init multiprocessing.Pool()\n",
    "pool = mp.Pool(int(mp.cpu_count()))\n",
    "\n",
    "# Step 2: `pool.apply` the `howmany_within_range()`\n",
    "bins = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "mi = 20\n",
    "\n",
    "pool.starmap(calculateBinOSMPolygon_distance_Disk, [(df, n,  mi) for n in bins])\n",
    "pool.starmap(calculateBinOSMRoadsLines_distance_Disk, [(df, n,  mi, True) for n in bins])\n",
    "pool.starmap(calculateBinOSMRoadsLines_distance_Disk, [(df, n,  mi, False) for n in bins])\n",
    "pool.starmap(calculateBinOSMPoints_dst_Disk, [(df, n,  mi) for n in bins])\n",
    "\n",
    "\n",
    "# Step 3: Don't forget to close\n",
    "pool.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c960ebc558cb47a91b30b6a69e09ee33d8511507a0164b187e789d12f3a22a9"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
